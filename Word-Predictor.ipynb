{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21b72b62",
   "metadata": {},
   "source": [
    "## <span style=\"font-family: Cambria;\">Word Predictor using N-Gram</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8afed7",
   "metadata": {},
   "source": [
    "<span style=\"font-family: Cambria;\">in this project we want to make simple word predictor system with the idea of n grams. it's a simple project in the realm of NLP.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa70c7d",
   "metadata": {},
   "source": [
    "### <span style=\"font-family: Cambria;\">Step 0 : importing our corpus</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4bedbc",
   "metadata": {},
   "source": [
    "<span style=\"font-family: Cambria;\"> in this step we read our text corpora from our local machine to our code:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e813bc23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File read successfully.\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "\n",
    "file_path = r'E:\\Study\\University\\codes\\Jupyter\\Datasets\\Hamshahri-Corpus\\Hamshahri-Corpus.txt'\n",
    "\n",
    "try:\n",
    "    with codecs.open(file_path, 'r', encoding='utf-8', errors='replace') as file:\n",
    "        text = file.read()\n",
    "        print(\"File read successfully.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found at path: {file_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c044e93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".DID\t1S1\r\n",
      ".Date\t75\\04\\02\r\n",
      ".Cat\tadabh\r\n",
      "جاودانگي در زندگي گروهي از طريق هنر \n",
      "نگاهي به نمايشگاه آثار هنري احمد طباطبايي \n",
      "موضوع آثار طباطبايي مورچگان هستند ولي در باطن چنين ظاهري، اين \n",
      "انسانهاهستند كه در هيبتي حشره گونه در تابلوهاي نقاشي نمايشگر \n",
      "گوشه هايي از زندگي خود هستند. \n",
      "مورچه اي را ديده ايم كه بار سنگين خودرا به دوش مي كشد و در بين راه \n",
      "خسته مي شود يا در نتيجه پيش آمدن يك حادثه اتفاقي بار از دستش رها \n",
      "شده و براي گريز از خطر آن را مي گذارد و فرار مي كند. اما ساعتي بعد \n",
      "به همان نقطه برمي گردد و\n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb744fda",
   "metadata": {},
   "source": [
    "### <span style=\"font-family: Cambria;\">Step 1: Preprocessing </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33ac845f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Text:\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "جاودانگي در زندگي گروهي از طريق هنر \n",
      "نگاهي به نمايشگاه آثار هنري احمد طباطبايي \n",
      "موضوع آثار طباطبايي مورچگان هستند ولي در باطن چنين ظاهري، اين \n",
      "انسانهاهستند كه در هيبتي حشره گونه در تابلوهاي نقاشي نمايشگر \n",
      "گوشه هايي از زندگي خود هستند. \n",
      "مورچه اي را ديده ايم كه بار سنگين خودرا به دوش مي كشد و در بين راه \n",
      "خسته مي شود يا در نتيجه پيش آمدن يك حادثه اتفاقي بار از دستش رها \n",
      "شده و براي گريز از خطر آن را مي گذارد و فرار مي كند. اما ساعتي بعد \n",
      "به همان نقطه برمي گردد و بار را دوباره به دوش كشيده نفس زنان و \n",
      "عرق ريزان آن را به منزل او مي رساند مي داند كه اگر در ميان راه از \n",
      "بين رفت، يك مورچه ديگر با همان استعداد غريزه عملي را كه او شروع \n",
      "كرده به پايان مي رساند. پس او مي داند كه بعد از خودش نسل آينده اي \n",
      "وجود دارد كه بايد از مزاياي آن استفاده نمايد. چه داستان درازي، \n",
      "انتها و پاياني هم ميليونها ندارد سال گذشته، ميلياردها سال ديگر \n",
      "خواهد گذشت وهمين برنامه ميليونها بار ديگر تجديد مي شود. پس بايد گفت \n",
      "سير حيات و تكامل پايان ناپذير است. اسرار جهان پاياني ندارد. پس \n",
      "اگر بخواهيم به يك چيز پايان ناپذ\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# a function that matches my regexes with the text string and remove them to reduce the size and dimensions\n",
    "\n",
    "def remove_pattern_matches(pattern, text):\n",
    "    # Find all matches using the provided pattern\n",
    "    matches = re.findall(pattern, text)\n",
    "    \n",
    "    # Remove lines matching the pattern from the text\n",
    "    modified_text = re.sub(pattern, '', text)\n",
    "    \n",
    "    return modified_text, matches\n",
    "\n",
    "# Define the pattern\n",
    "pattern = r'\\.(DID|Date|Cat)\\s+\\S+'\n",
    "\n",
    "# Call the function\n",
    "clean_text, matches = remove_pattern_matches(pattern, text)\n",
    "\n",
    "# Print the modified text and the matched patterns\n",
    "print(\"Modified Text:\")\n",
    "print(clean_text[:1000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c9dd64",
   "metadata": {},
   "source": [
    "### <span style=\"font-family: Cambria;\">Step 2: Creating our standard dataset</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4964ed7e",
   "metadata": {},
   "source": [
    "<span style=\"font-family: Cambria;\">in this step i save my new text into an txt file. so now after this step we have a standard and clead text for processing</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a0414c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The string has been written to E:\\Study\\University\\codes\\Jupyter\\Datasets\\Hamshahri-Corpus\\clean.txt\n"
     ]
    }
   ],
   "source": [
    "file_path = r'E:\\Study\\University\\codes\\Jupyter\\Datasets\\Hamshahri-Corpus\\clean.txt'\n",
    "\n",
    "with open(file_path, 'w', encoding='utf-8') as file:\n",
    "    file.write(clean_text)\n",
    "\n",
    "print(f\"The string has been written to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8814241",
   "metadata": {},
   "source": [
    "### <span style=\"font-family: Cambria;\">Step 3:Create our matrixes</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b82b251",
   "metadata": {},
   "source": [
    "<span style=\"font-family: Cambria;\">In this step we use our clean data to create 3 matrixes :\n",
    "    <br>1)Tokens matrix\n",
    "    <br>2)Bigram matrix\n",
    "    <br>3)Trigram matrix\n",
    "    <br>\n",
    "    in this three matrices we count every combination and save it into seperate csv files. we do this step only once for our project and while our matrices are ready we just work with their data and we don't need to create this matrices every time we run this code.\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6717970",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\kiarash rahmani\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\kiarash rahmani\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\kiarash rahmani\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\kiarash rahmani\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kiarash rahmani\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kiarash rahmani\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "513ae379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been saved to starters_sorted.csv.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "text_file_path = r'E:\\Study\\University\\codes\\Jupyter\\Datasets\\Hamshahri-Corpus\\clean.txt'\n",
    "\n",
    "with open(text_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    dataset = file.read()\n",
    "\n",
    "sentences = sent_tokenize(dataset)\n",
    "\n",
    "first_words = [word_tokenize(sentence)[0] for sentence in sentences]\n",
    "\n",
    "word_counts = Counter(first_words)\n",
    "\n",
    "sentence_count = len(sentences)\n",
    "\n",
    "df = pd.DataFrame.from_dict(word_counts, orient='index', columns=['Count'])\n",
    "df.index.name = 'First Word'\n",
    "df['Percentage of Sentences'] = df['Count'] / sentence_count * 100\n",
    "\n",
    "df_sorted = df.sort_values(by='Count', ascending=False)\n",
    "\n",
    "csv_file_path = \"starters_sorted.csv\"\n",
    "df_sorted.to_csv(csv_file_path, encoding='utf-8')\n",
    "\n",
    "print(f\"Results have been saved to {csv_file_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "085773a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>First Word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>در</th>\n",
       "      <td>147208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>به</th>\n",
       "      <td>105698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>وي</th>\n",
       "      <td>102161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>اين</th>\n",
       "      <td>92867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>از</th>\n",
       "      <td>36050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>اما</th>\n",
       "      <td>35304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>با</th>\n",
       "      <td>26356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>*</th>\n",
       "      <td>24454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>23333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>او</th>\n",
       "      <td>18999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Count\n",
       "First Word        \n",
       "در          147208\n",
       "به          105698\n",
       "وي          102161\n",
       "اين          92867\n",
       "از           36050\n",
       "اما          35304\n",
       "با           26356\n",
       "*            24454\n",
       "-            23333\n",
       "او           18999"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sorted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2b18a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens frequencies saved to token_frequencies.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "\n",
    "sent = clean_text.split()\n",
    "tokens = list(ngrams(sent, 1))\n",
    "tokens_counts = Counter(tokens)\n",
    "df_tok = pd.DataFrame(list(tokens_counts.items()), columns=['tokens', 'Frequency'])\n",
    "\n",
    "csv_file_path = \"token_frequencies.csv\"\n",
    "\n",
    "df_tok.to_csv(csv_file_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"Tokens frequencies saved to {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad762a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(جاودانگي,)</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(در,)</td>\n",
       "      <td>2131406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(زندگي,)</td>\n",
       "      <td>42849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(گروهي,)</td>\n",
       "      <td>10868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(از,)</td>\n",
       "      <td>1441784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(طريق,)</td>\n",
       "      <td>25472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(هنر,)</td>\n",
       "      <td>13034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(نگاهي,)</td>\n",
       "      <td>5187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(به,)</td>\n",
       "      <td>1870277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(نمايشگاه,)</td>\n",
       "      <td>24798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tokens  Frequency\n",
       "0  (جاودانگي,)        219\n",
       "1        (در,)    2131406\n",
       "2     (زندگي,)      42849\n",
       "3     (گروهي,)      10868\n",
       "4        (از,)    1441784\n",
       "5      (طريق,)      25472\n",
       "6       (هنر,)      13034\n",
       "7     (نگاهي,)       5187\n",
       "8        (به,)    1870277\n",
       "9  (نمايشگاه,)      24798"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tok.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e301bcbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram frequencies saved to bigram_frequencies.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "\n",
    "sent = clean_text.split()\n",
    "bigrams = list(ngrams(sent, 2))\n",
    "bigram_counts = Counter(bigrams)\n",
    "df = pd.DataFrame(list(bigram_counts.items()), columns=['Bigram', 'Frequency'])\n",
    "\n",
    "csv_file_path = \"bigram_frequencies.csv\"\n",
    "\n",
    "df.to_csv(csv_file_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"Bigram frequencies saved to {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "45bd823d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bigram</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(جاودانگي, در)</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(در, زندگي)</td>\n",
       "      <td>3654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(زندگي, گروهي)</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(گروهي, از)</td>\n",
       "      <td>3754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(از, طريق)</td>\n",
       "      <td>21582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(طريق, هنر)</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(هنر, نگاهي)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(نگاهي, به)</td>\n",
       "      <td>2755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(به, نمايشگاه)</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(نمايشگاه, آثار)</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Bigram  Frequency\n",
       "0    (جاودانگي, در)          7\n",
       "1       (در, زندگي)       3654\n",
       "2    (زندگي, گروهي)         18\n",
       "3       (گروهي, از)       3754\n",
       "4        (از, طريق)      21582\n",
       "5       (طريق, هنر)         13\n",
       "6      (هنر, نگاهي)          1\n",
       "7       (نگاهي, به)       2755\n",
       "8    (به, نمايشگاه)        283\n",
       "9  (نمايشگاه, آثار)       1057"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a9976c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram frequencies saved to trigram_frequencies.csv\n"
     ]
    }
   ],
   "source": [
    "# return all the 3 word combinations for trigrams \n",
    "sent = clean_text.split()\n",
    "trigrams = list(ngrams(sent, 3))\n",
    "trigram_counts = Counter(trigrams)\n",
    "df_tri = pd.DataFrame(list(trigram_counts.items()), columns=['Trigram', 'Frequency'])\n",
    "\n",
    "csv_file_path = \"trigram_frequencies.csv\"\n",
    "\n",
    "df_tri.to_csv(csv_file_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"Trigram frequencies saved to {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ba7920a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trigram</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(جاودانگي, در, زندگي)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(در, زندگي, گروهي)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(زندگي, گروهي, از)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(گروهي, از, طريق)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(از, طريق, هنر)</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(طريق, هنر, نگاهي)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(هنر, نگاهي, به)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(نگاهي, به, نمايشگاه)</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(به, نمايشگاه, آثار)</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(نمايشگاه, آثار, هنري)</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Trigram  Frequency\n",
       "0   (جاودانگي, در, زندگي)          2\n",
       "1      (در, زندگي, گروهي)          3\n",
       "2      (زندگي, گروهي, از)          3\n",
       "3       (گروهي, از, طريق)          5\n",
       "4         (از, طريق, هنر)         13\n",
       "5      (طريق, هنر, نگاهي)          1\n",
       "6        (هنر, نگاهي, به)          1\n",
       "7   (نگاهي, به, نمايشگاه)         30\n",
       "8    (به, نمايشگاه, آثار)         11\n",
       "9  (نمايشگاه, آثار, هنري)        146"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tri.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054ed3a6",
   "metadata": {},
   "source": [
    "### <span style=\"font-family: Cambria;\">Step 4:Word Predicting</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8a9a65",
   "metadata": {},
   "source": [
    " <span style=\"font-family: Cambria;\">In the process of developing our language model, we leverage the clean and prepared corpus as the foundation. At this stage, the focus is on utilizing 2-grams (bigrams) and 3-grams (trigrams) to calculate matrices and probabilities. This step forms the core and essence of our project, serving as the brain that powers our word predictor.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b886d48",
   "metadata": {},
   "source": [
    " <span style=\"font-family: Cambria;\">now everything is ready to take our last step to completing this project so we should calculate possibilities:</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0c8ef5",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: Cambria;\">Step 4-1: Bigram</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b0d81d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your text: آن جا منزل او\n",
      "Last two words: ['منزل', 'او']\n",
      "Last word: او\n"
     ]
    }
   ],
   "source": [
    "# Receiving input from the user\n",
    "user_input = input(\"Enter your text: \")\n",
    "word_list = user_input.split()\n",
    "last_word = word_list[-1]\n",
    "last_two_words = word_list[-2:]\n",
    "\n",
    "print(\"Last two words:\", last_two_words)\n",
    "print(\"Last word:\", last_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c856b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to 'biresult.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to search for a bigram where the first word is determined base on user input and return its count\n",
    "def search_bigram_starting_with(csv_file, starting_word):\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Convert the string of the tuple to an actual tuple\n",
    "    df['Bigram'] = df['Bigram'].apply(eval)\n",
    "\n",
    "    result = df[df['Bigram'].apply(lambda x: x[0] == starting_word)][['Bigram', 'Frequency']]\n",
    "\n",
    "    if not result.empty:\n",
    "        return result\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "csv_file_path = 'bigram_frequencies.csv'\n",
    "starting_word = last_word\n",
    "\n",
    "result_df = search_bigram_starting_with(csv_file_path, starting_word)\n",
    "if not result_df.empty:\n",
    "    result_df = result_df.sort_values(by='Frequency', ascending=False)\n",
    "    \n",
    "if not result_df.empty:\n",
    "    result_df.to_csv('biresult.csv', index=False)\n",
    "    print(f\"Results saved to 'biresult.csv'\")\n",
    "else:\n",
    "    print(f\"No bigrams starting with '{starting_word}' found in the CSV file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d188c870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The count of 'او' is: 108505\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def search_token(csv_file, target_word):\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    result = df[df['tokens'].apply(lambda x: eval(x)[0]) == target_word]['Frequency']\n",
    "\n",
    "    if not result.empty:\n",
    "        return result.iloc[0]  # there is only one row for each word\n",
    "    else:\n",
    "        return 0 \n",
    "\n",
    "\n",
    "csv_file_path = 'token_frequencies.csv'\n",
    "word_to_search = last_word\n",
    "count = search_token(csv_file_path, word_to_search)\n",
    "\n",
    "print(f\"The count of '{word_to_search}' is: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d2e34c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('را', 15816), ('در', 8610), ('به', 6047), ('مي', 4847), ('از', 3095), ('با', 3012), ('و', 1801), ('كه', 1680), ('نيز', 1162), ('براي', 1150)]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_second_element(csv_file, num_values=10):\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Assuming the column containing tuples is named 'Bigram' and the column containing counts is named 'Frequency'\n",
    "    data_list = []\n",
    "\n",
    "    for i in range(min(num_values, len(df))):\n",
    "        bigram_tuple = eval(df['Bigram'].iloc[i])\n",
    "        second_element = bigram_tuple[1] if len(bigram_tuple) > 1 else None\n",
    "        frequency = df['Frequency'].iloc[i]\n",
    "        data_list.append((second_element, frequency))\n",
    "\n",
    "    return data_list\n",
    "\n",
    "csv_file_path = 'biresult.csv'\n",
    "num_values_to_extract = 10\n",
    "result_data = extract_second_element(csv_file_path, num_values=num_values_to_extract)\n",
    "\n",
    "# Printing the result\n",
    "print(result_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11b7c859",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('را', 0.14576286807059582), ('در', 0.07935118197318096), ('به', 0.05573015068430026), ('مي', 0.0446707524998848), ('از', 0.02852403115063822), ('با', 0.027759089442882818), ('و', 0.016598313441776875), ('كه', 0.015483157458181651), ('نيز', 0.010709183908575642), ('براي', 0.010598589926731487)]\n"
     ]
    }
   ],
   "source": [
    "def divide_numbers(original_list, count):\n",
    "    new_list = [(word, freq / count) for word, freq in original_list]\n",
    "    return new_list\n",
    "\n",
    "\n",
    "new_count= int(count)\n",
    "result_list = divide_numbers(result_data, new_count)\n",
    "# Printing the result\n",
    "print(result_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bf14ef",
   "metadata": {},
   "source": [
    "#### <span style=\"font-family: Cambria;\">Step 4-2: Trigram</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b794399",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to 'triresult.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to search for a trigram where the first and second words match the user input and return its count\n",
    "def search_trigram_starting_with(csv_file, starting_words):\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Convert the string of the tuple to an actual tuple\n",
    "    df['Trigram'] = df['Trigram'].apply(eval)\n",
    "\n",
    "    result = df[df['Trigram'].apply(lambda x: x[0] == starting_words[0] and x[1] == starting_words[1])][['Trigram', 'Frequency']]\n",
    "\n",
    "    if not result.empty:\n",
    "        return result\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "csv_file_path = 'trigram_frequencies.csv'\n",
    "starting_words = last_two_words  \n",
    "\n",
    "result_df = search_trigram_starting_with(csv_file_path, starting_words)\n",
    "if not result_df.empty:\n",
    "    result_df = result_df.sort_values(by='Frequency', ascending=False)\n",
    "\n",
    "if not result_df.empty:\n",
    "    result_df.to_csv('triresult.csv', index=False)\n",
    "    print(f\"Results saved to 'triresult.csv'\")\n",
    "else:\n",
    "    print(f\"No Trigram starting with '{starting_words}' found in the CSV file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ccaa3a4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "منزل\n",
      "او\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trigram</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3067860</th>\n",
       "      <td>(منزل, او, را)</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5096369</th>\n",
       "      <td>(منزل, او, به)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15546927</th>\n",
       "      <td>(منزل, او, در)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>(منزل, او, مي)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29472675</th>\n",
       "      <td>(منزل, او, كه)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26295983</th>\n",
       "      <td>(منزل, او, نزديك)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27055744</th>\n",
       "      <td>(منزل, او, مورد)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27421546</th>\n",
       "      <td>(منزل, او, گردهم)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28170022</th>\n",
       "      <td>(منزل, او, نگشت.)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29777189</th>\n",
       "      <td>(منزل, او, يورش)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Trigram  Frequency\n",
       "3067860      (منزل, او, را)          7\n",
       "5096369      (منزل, او, به)          3\n",
       "15546927     (منزل, او, در)          3\n",
       "110          (منزل, او, مي)          2\n",
       "29472675     (منزل, او, كه)          1\n",
       "26295983  (منزل, او, نزديك)          1\n",
       "27055744   (منزل, او, مورد)          1\n",
       "27421546  (منزل, او, گردهم)          1\n",
       "28170022  (منزل, او, نگشت.)          1\n",
       "29777189   (منزل, او, يورش)          1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(starting_words[0])\n",
    "print(starting_words[1])\n",
    "result_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "187aa20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The count of '['منزل', 'او']' is: 43\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def search_tri_token(csv_file, target_word):\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    target_word_str = f\"('{target_word[0]}', '{target_word[1]}')\"\n",
    "\n",
    "    result = df[df['Bigram'] == target_word_str]['Frequency'].values\n",
    "\n",
    "    if len(result) > 0:\n",
    "        return result[0]  # return the count directly\n",
    "    else:\n",
    "        return 0 \n",
    "\n",
    "csv_file_path = 'bigram_frequencies.csv'\n",
    "word_to_search = last_two_words\n",
    "count_tri = search_tri_token(csv_file_path, word_to_search)\n",
    "\n",
    "print(f\"The count of '{word_to_search}' is: {count_tri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1282ca6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "print(count_tri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "021a936e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('را', 7), ('به', 3), ('در', 3), ('مي', 2), ('كه', 1), ('نزديك', 1), ('مورد', 1), ('گردهم', 1), ('نگشت.', 1), ('يورش', 1)]\n"
     ]
    }
   ],
   "source": [
    "# i should collect third element\n",
    "import pandas as pd\n",
    "\n",
    "def tri_extract_second_element(csv_file, num_values=10):\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Assuming the column containing tuples is named 'Trigram' and the column containing counts is named 'Frequency'\n",
    "    data_list = []\n",
    "\n",
    "    for i in range(min(num_values, len(df))):\n",
    "        Trigram_tuple = eval(df['Trigram'].iloc[i])\n",
    "        third_element = Trigram_tuple[2] if len(Trigram_tuple) > 1 else None\n",
    "        frequency = df['Frequency'].iloc[i]\n",
    "        data_list.append((third_element, frequency))\n",
    "\n",
    "    return data_list\n",
    "\n",
    "tri_res_csv_file_path = 'triresult.csv'\n",
    "num_values_to_extract = 10\n",
    "tri_result_data = tri_extract_second_element(tri_res_csv_file_path, num_values=num_values_to_extract)\n",
    "\n",
    "print(tri_result_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1a2e031b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('را', 0.16279069767441862), ('به', 0.06976744186046512), ('در', 0.06976744186046512), ('مي', 0.046511627906976744), ('كه', 0.023255813953488372), ('نزديك', 0.023255813953488372), ('مورد', 0.023255813953488372), ('گردهم', 0.023255813953488372), ('نگشت.', 0.023255813953488372), ('يورش', 0.023255813953488372)]\n"
     ]
    }
   ],
   "source": [
    "def divide_numbers(original_list, count):\n",
    "    new_list = [(word, freq / count) for word, freq in original_list]\n",
    "    return new_list\n",
    "\n",
    "new_count= int(count_tri)\n",
    "tri_result_list = divide_numbers(tri_result_data, new_count)\n",
    "# Printing the result\n",
    "print(tri_result_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e6d2d7",
   "metadata": {},
   "source": [
    "### <span style=\"font-family: Cambria;\">Step 5: Final Results</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54209973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram result:\n",
      "را: 14.6% درصد\n",
      "در: 7.9% درصد\n",
      "به: 5.6% درصد\n",
      "مي: 4.5% درصد\n",
      "از: 2.9% درصد\n",
      "با: 2.8% درصد\n",
      "و: 1.7% درصد\n",
      "كه: 1.5% درصد\n",
      "نيز: 1.1% درصد\n",
      "براي: 1.1% درصد\n",
      "Bigram result:\n",
      "را: 16.3% درصد\n",
      "به: 7.0% درصد\n",
      "در: 7.0% درصد\n",
      "مي: 4.7% درصد\n",
      "كه: 2.3% درصد\n",
      "نزديك: 2.3% درصد\n",
      "مورد: 2.3% درصد\n",
      "گردهم: 2.3% درصد\n",
      "نگشت.: 2.3% درصد\n",
      "يورش: 2.3% درصد\n"
     ]
    }
   ],
   "source": [
    "def divide_numbers(original_list, count):\n",
    "    new_list = [(word, round(freq / count, 3)) for word, freq in original_list]\n",
    "    return new_list\n",
    "\n",
    "\n",
    "new_count= int(count)\n",
    "result_list = divide_numbers(result_data, count)\n",
    "\n",
    "sorted_result = sorted(result_list, key=lambda x: x[1], reverse=True)\n",
    "print(\"Bigram result:\")\n",
    "for i, (word, probability) in enumerate(sorted_result[:10], 1):\n",
    "    percentage = round(probability * 100, 3)\n",
    "    print(f\"{word}: {percentage}% درصد\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def divide_numbers(original_list, count):\n",
    "    new_list = [(word, round(freq / count_tri, 3)) for word, freq in original_list]\n",
    "    return new_list\n",
    "\n",
    "\n",
    "new_count= int(count)\n",
    "tri_result_list = divide_numbers(tri_result_data, count)\n",
    "\n",
    "sorted_result = sorted(tri_result_list, key=lambda x: x[1], reverse=True)\n",
    "print(\"Bigram result:\")\n",
    "for i, (word, probability) in enumerate(sorted_result[:10], 1):\n",
    "    percentage = round(probability * 100, 3)\n",
    "    print(f\"{word}: {percentage}% درصد\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0880f4a5",
   "metadata": {},
   "source": [
    "### <span style=\"font-family: Cambria;\">Thanks for your time! </span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
